---
title: "MovieLens Recommendation Sysstem"
author: "Fr√©deric Van der Cruyssen"
date: "3/15/2021"
output: pdf_document
---

# Introduction
In this capstone project we want to predict user movie rating based on a large dataframe "the Movielens 10M database". We start off with creating the datasets and doing some exploration of the data. Next, we will build a simple linear model and further refine it towards an accurate final model to predict user movie ratings. 

## Creating datasets

```{r install and create datasets}
if(!require(tidyverse)) install.packages("tidyverse", repos = "http://cran.us.r-project.org")
if(!require(caret)) install.packages("caret", repos = "http://cran.us.r-project.org")
if(!require(data.table)) install.packages("data.table", repos = "http://cran.us.r-project.org")
library(tidyverse)
library(DescTools)
library(tinytex)
knitr::opts_chunk$set(echo = FALSE)

# MovieLens 10M dataset:
# https://grouplens.org/datasets/movielens/10m/
# http://files.grouplens.org/datasets/movielens/ml-10m.zip

dl <- tempfile()
download.file("http://files.grouplens.org/datasets/movielens/ml-10m.zip", dl)

ratings <- fread(text = gsub("::", "\t", readLines(unzip(dl, "ml-10M100K/ratings.dat"))),
                 col.names = c("userId", "movieId", "rating", "timestamp"))

movies <- str_split_fixed(readLines(unzip(dl, "ml-10M100K/movies.dat")), "\\::", 3)
colnames(movies) <- c("movieId", "title", "genres")

movies <- as.data.frame(movies) %>% mutate(movieId = as.numeric(movieId),
                                           title = as.character(title),
                                           genres = as.character(genres))


movielens <- left_join(ratings, movies, by = "movieId")

# We create a test set based on 10% of the total edx set. 
test_index <- createDataPartition(y = movielens$rating, times = 1, p = 0.1, list = FALSE)
edx <- movielens[-test_index,]
temp <- movielens[test_index,]

# We verify if movieId and UserId are also present in both validation and test set. 

validation <- temp %>% 
  semi_join(edx, by = "movieId") %>%
  semi_join(edx, by = "userId")

# Removed rows are back added to the edx set to continue calculations.

removed <- anti_join(temp, validation)
edx <- rbind(edx, removed)

rm(dl, ratings, movies, test_index, temp, movielens, removed)

```

## Overview of dataset
We arrange the dataset by number of ratings en number of movies with a signle rating. We can see that there are 10.000 movies with 10 million ratings. The most rated movie is Pulp Fiction. 

```{r initial_inquiries, echo=TRUE}
# Most rated films
edx %>% group_by(title) %>%
  summarize(n_ratings = n()) %>%
  arrange(desc(n_ratings))

# Number of movies rated once
edx %>% group_by(title) %>%
  summarize(n_ratings = n()) %>%
  filter(n_ratings==1) %>%
  count() %>% pull()
```

## Overview of columns
We have split the dataset in a training and test set. The test set consists of 999.988 rows and 6 columns.

```{r glimpse_data, echo=TRUE}
glimpse(validation)
```

## Basic model
We start with a simple model by using the average method and calculate RMSE.

```{r}
mu <- mean(edx$rating)
RMSE(validation$rating, mu)
```
## Improving the model
Next we'll try to improve the model by adding an error factor b_i to the equation and calculate RMSE and the qplot for the distribution of b_i's.

```{r}
b_i <- edx %>%
  group_by(movieId) %>%
  summarize(b_i = mean(rating - mu))
predicted_ratings <- validation %>% 
  left_join(b_i, by='movieId') %>%
  mutate(pred = mu + b_i) %>%
  pull(pred)

RMSE(validation$rating, predicted_ratings)
qplot(b_i, data = b_i, bins = 15, color = I("black"))

```

## Further refinements
We refine the model by adding extreme user ratings, b_u, into the equation. We rerun the analysis and calculate RMSE.

```{r}
b_u <- edx %>% 
  left_join(b_i, by='movieId') %>%
  group_by(userId) %>%
  summarize(b_u = mean(rating - mu - b_i))

predicted_ratings <- validation %>% 
  left_join(b_i, by='movieId') %>%
  left_join(b_u, by='userId') %>%
  mutate(pred = mu + b_i + b_u) %>%
  pull(pred)

RMSE(predicted_ratings, validation$rating)

```

## Regularization
We want to remove large errors in the prediction model by using regularization.

```{r}
lambdas <- seq(from=0, to=10, by=0.25)
rmses <- sapply(lambdas, function(l){
  mu <- mean(edx$rating)
  b_i <- edx %>% 
    group_by(movieId) %>%
    summarize(b_i = sum(rating - mu)/(n()+l))
  b_u <- edx %>% 
    left_join(b_i, by="movieId") %>%
    group_by(userId) %>%
    summarize(b_u = sum(rating - b_i - mu)/(n()+l))
  predicted_ratings <- validation %>% 
    left_join(b_i, by = "movieId") %>%
    left_join(b_u, by = "userId") %>%
    mutate(pred = mu + b_i + b_u) %>%
    pull(pred)
  return(RMSE(predicted_ratings, validation$rating))
})

qplot(lambdas, rmses)
min(rmses)

```

## Final model
The final model RMSE now becomes:
```{r}
lam <- lambdas[which.min(rmses)]

b_i <- edx %>% 
  group_by(movieId) %>%
  summarize(b_i = sum(rating - mu)/(n()+lam))
b_u <- edx %>% 
  left_join(b_i, by="movieId") %>%
  group_by(userId) %>%
  summarize(b_u = sum(rating - b_i - mu)/(n()+lam))
predicted_ratings <- validation %>% 
  left_join(b_i, by = "movieId") %>%
  left_join(b_u, by = "userId") %>%
  mutate(pred = mu + b_i + b_u) %>%
  pull(pred)
RMSE(predicted_ratings, validation$rating)
```

# Conclusion
We summarize the RMSE for each model built:

We can see incremental improvements to the RMSE as we supplant our model with bias terms and regularization.

| Method                             | RMSE     |
|------------------------------------|----------|
| Average                            | 1.060219 |
| Movie effect                       | 0.9439066|
| Movie and user effects             | 0.8656791|
| Final model                        | 0.8651767|

